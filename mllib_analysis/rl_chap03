= an equality relationship that is true by definition
E[X] expectation of random variable X
Pr{X = x} probability that the random variable X takes on the value x
arg maxa f (a) a value of a at which f (a) takes its maximal value
ε probability of taking a random action in an ε-greedy policy
α, β step-size parameters
γ discount-rate parameter
λ decay-rate parameter for eligibility traces
In a bandit problem:
k number of actions/arms
q∗(a) true value of action a
Qt(a) estimate at time t of q∗(a)
Nt(a) the number of times action a has been selected up through time t
Ht(a) learned preference for selecting action a
In a Markov Decision Process:
s, s1 states
a action
r reward
S set of all nonterminal states
S+ set of all states, including the terminal state
A(s) set of all actions possible in state s
R set of all possible rewards
t discrete time step
T, T (t) final time step of an episode, or of the episode including time t
At action at time t
St state at time t, typically due, stochastically, to St−1 and At−1
